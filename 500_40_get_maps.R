#' ---
#' title: "Mapping Samples for Conference Presentation(s)"
#' author: "Paul Czechowski"
#' date: "October 3, 2018"
#' output: pdf_document
#' toc: true
#' highlight: zenburn
#' 
#' ---
#'
#' # Preface
#' 
#' `rmarkdown::render ("/Users/paul/Documents/CU_combined/Github/500_40_get_maps.R")`.
#' Please check the session info at the end of the document for further 
#' notes on the coding environment.
#'
#' # Environment preparation
#'
#' ## Package loading and cleaning of workspace
#+ message=FALSE, results='hide'

# library ("matrixStats") # here used (anymore?) for column median
library ("readxl")      # to open excel files
library ("reshape2")    # plotting, table manipulation
library ("ggplot2")     # plotting, mapping
library ("tidyverse")   # to `write_excel_csv()`
library ("maps")        # mapping
library ("ggrepel")     # plot labelling
library ("grid")        # handle graphical objects
library ("gridExtra")   # handle graphical objects

#' ## Flushing buffer
#' 
rm(list=ls())     # for safety only

#' 
#' ## Functions
#'
'%!in%' <- function(x,y)!('%in%'(x,y))

#' 
#' # Data import
#' 
#' Data is imported using basic R functionality, and was generated by these scripts: 
#'
#'  *  `/Users/paul/Documents/CU_combined/Github/500_10_gather_predictor_tables.R`
#'  *  `/Users/paul/Documents/CU_combined/Github/500_20_get_predictor_euklidian_distances.R`

load (file = 
   "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_30_shape_matrices__output_predictor_data.Rdata")

#' # Formatting local sample inventory
#' 
#' ## Adding `PID`'s to sample inventory 
#' 
#' Adding port IDs (`"PTID"`) to sampled ports in inventory file.
#' Can't find Pearl Harbor in places file - likely because it is a
#' military base (Jim Corbett). 23.8.2017: I am using Honolulus port ID from
#' the Lloyd data for samples from Pearl Harbor. Pearl Harbour
#' previously was marked `"0000"`, now `"2503"`. This ID will now in the
#' data twice - be mindful of possible bugs downstream!

# get port names from inventory file for MANUAL lookup 
smpld_PORT <- unique (src_heap$INVE$PORT)

# added 25.04.2018 and 31.08.2018 - added ports for which re-processing from old project data
#  was accomplished. This list will not grow so this is a (possibly shaky)
#  solution. The proper (?) Alternative _may_ be to add these samples to `src_heap$INVE$PORT`
#  via the input file in `/Users/paul/Documents/CU_combined/Github/500_10_gather_predictor_tables.R`
smpld_PORT <- append(smpld_PORT, c("Adelaide", "Chicago", "Singapore", 
                                   "Zeebrugge", "Ghent", "Antwerp", 
                                   "Rotterdam", "Buenos Aires", "Puerto Madryn",
                                   "Iqaluit"))

#' Manual lookup of sampled ports via 
#' `open /Users/paul/Dropbox/NSF\ NIS-WRAPS\ Data/raw\ data\ for\ Mandana/PlacesFile_updated_Aug2017.xlsx -a "Microsoft Excel"`
#' This file needs to be the same as used by `~/Box\ Sync/CU_NIS-WRAPS/170720_code/170830_10_cleanup_tables.R`.
# must match order of `smpld_PORT`

#  alternatively try a fuzzy match with agrep()
#  Milne Inlet coded as Nanisivik (3371)
#  Pearl Harbour coded as Honolulu (2503)
# [1] "Haines_AK_USA"          "Coos_Bay_OR_USA"        "Guam_Apra_Harbor_USA"   "Nanaimo_BC_Canada"      "Long_Beach_CA_USA"      "Vancouver_BC_Canada"    "Pearl_Harbor_HI_USA"   
# [8] "Honolulu_Harbor_HI_USA" "Portland_OR_USA"        "Churchill_MB_Canada"    "Oakland_CA_USA"         "Richmond_VA_USA"        "Wilmington_DE_USA"      "New_Orleans_LA_USA"    
# [15] "Miami_FL_USA"           "Houston_TX_USA"         "Baltimore_MD_USA"       "Milne_Inlet_NU_CAN"     "Adelaide"               "Chicago"                "Singapore"             
# [22] "Zeebrugge"              "Ghent"                  "Antwerp"                "Rotterdam"              "Buenos Aires"           "Puerto Madryn"          "Iqaluit"               

# Correct names. "*": Nearest port in port database chosen for actual location.
smpld_PORT <- c("Haines", "Coos Bay", "Guam Apra", "Nanaimo", "Long Beach", "Vancouver", "Pearl Harbor*",
                "Honolulu",  "Portland", "Churchill", "Oakland", "Richmond", "Wilmington", "New_Orleans",
                "Miami", "Houston", "Baltimore", "Milne Inlet*", "Adelaide", "Chicago", "Singapore",
                "Zeebrugge", "Ghent", "Antwerp", "Rotterdam", "Buenos Aires", "Puerto Madryn", "Iqaluit")               


smpld_PID <- c("3367", "2141", "2111", "3108", "7597", "311", "2503",
               "2503",  "238", "4021", "7598", "7976", "7975", "3381",
               "4899", "2331",  "854", "3371", "3110", "2907", "1165",
               "1675", "4538",  "576",  "830", "2729", "193", "5362")

# create concise inventory tibble 
 # 23.08.2017 duplicate harbour ID "2503" does not appear to be a problem

smpld <- data_frame (PORT = smpld_PORT, PTID = smpld_PID)

# this filename is variable and based on the script name 
save (smpld, file = 
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps_output__sampled_ports_df.Rdata")

#' # Selecting and ranking of routes connecting to samples in the freezer (now and in the future)
#'
#' ## Route filtering
#'
#' Route information is in `src_heap$ROUT`. Sampled port ids are in `smpld$PTID`
#' Defining sampled routes (`srout`) by matching sampled port ids with each other
#' at ends. Can be used to find all conncetion to unsample ports as well, of course.'

srout <- filter(src_heap$ROUT, 
  PRTA %in% smpld$PTID & PRTB %in% smpld$PTID |
  PRTB %in% smpld$PTID & PRTA %in% smpld$PTID )

#' ## Checking number of comple cases
#'
#' High value of complete cases desirable, other cases can't be sorted
#' Complete cases higher for `170804_all_connected_ports.csv` rather then the other
#' file (see above). The route table at hand has already been filtered to which
#' environmental distances are available `(see /Users/paul/Documents/CU_combined/Github/500_30_shape_matrices.R`
#' line 312. Consequently (?) data is complete:

sum(complete.cases(srout)) / length(complete.cases(srout))

#' Route data is incomplete no cases (see above comments):

srout [!complete.cases(srout), ] # %>% print(n = nrow(.))

#' ## Add port names and countries
#' 
#' Add port names and countries (not correcting coordinates). Incomplete cases 
#' to Jim Corbett? Port name information is here (and should be 9,177 x 5): 
ports <- src_heap$PORT 

#' Adding in port name information for both route ends:
srout <- left_join (srout, ports[c("PID", "PORT", "COUN")],
  by = c("PRTA" = "PID"))   
names (srout)[names (srout) %in% c("PORT", "COUN")] <- c("PORTA", "COUNA")

srout <- left_join (srout, ports[c("PID", "PORT", "COUN")],
  by = c("PRTB" = "PID"))   
names (srout)[names (srout) %in% c("PORT", "COUN")] <- c("PORTB", "COUNB")

#' ## Removing incomplete cases
#' 
#' Incomplete cases can't be sorted and should be reported.
#' I am removing them here.
srout <-  srout [ which (complete.cases (srout)), ] 


#' ## Saving comnected routes
#' 
#' Routes that connect our samples are saved:

# copying object - points depiction needs full table down below but
# `srout` will be shaped further in the following lines 

srout_all <- srout 
save (srout_all, file =
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps_output__considered_routes.Rdata")

#' ## Route filtering
#' 
#' Can be deactivated, modified.

# test 24.04.2018 - are test sample in the route table?
# 6 * 2 routes expected for Long Beach // Miami // Houston // Baltimore 
# selected_samples = c("7597","2331","4899","854")

# test 25.04.2018 - are test sample in the route table?
# manual lookup via
# open /Users/paul/Dropbox/NSF\ NIS-WRAPS\ Data/raw\ data\ for\ Mandana/PlacesFile_updated_Aug2017.xlsx -a "Microsoft Excel"
#                     PH",  "SP",  "AD",  "CH"    "MI"    "BT"   "HT"    "LB"


# 3.10.2018 - route subsetting on focussed routes has already been done on step up
# and doesn't need to be repeated. Selcted smaples is also needed for plotting, though
selected_samples = c("2503","1165", "1165", "3110", "2907", "854", "2503", "2331", "7597", "4899")
 
# ## CHANGE THIS LINE IF NECESSARY 
# srout <- srout %>% filter (PRTA %in% selected_samples | 
#                            PRTB %in% selected_samples ) # %>% print(n = nrow(.))


#' ## **Route ranking based on calculated rank**
#'
#' Ranking by `RISK` variable, printing, and keeping for mapping
us_world <- srout %>% arrange (desc (RISK), desc (ROUTE))  %>%  print(n = nrow(.))

#' Saving for R 
save (us_world, file =
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps_output__current_routes_sorted.Rdata")

#' Saving for humans and external viewers:
write_excel_csv (us_world, 
                 "/Users/paul/Documents/CU_combined/Zenodo/Results/500_40_get_maps_output__current_routes_sorted.csv",
                 na = "NA", append = FALSE, col_names = TRUE)

# ' ## **Route ranking based on environmental distance and trips** - skipped 3.10.2018 
# '
# ' Copying object, original object needs to be kept for mapping
# us_world_dt <- us_world  # %>% print(n = nrow(.))
# 
# ' Add grouping variable indicating quartiles of `TRIPS`
# 
# https://stackoverflow.com/questions/7508229/how-to-create-a-column-with-a-quartile-rank
# us_world_dt <- within (us_world_dt, TQRT <- as.integer (cut (TRIPS, quantile (TRIPS,
#   seq(0, 1, 1/3), na.rm = FALSE), include.lowest=TRUE))) # %>% print(n = nrow(.))
# 
# ' Add grouping variable indicating quartiles of `EDST`
# 
# us_world_dt <- within (us_world_dt, EQRT <- as.integer (cut (EDST, quantile (EDST,
#   seq(0, 1, 1/3), na.rm = FALSE), include.lowest=TRUE))) # %>%  print(n = nrow(.))
# 
# ' _"Sort routes by environmental similarity (temp & salinity index). Then deal only with the
# ' routes at the end of this continuum where ports that are being connected are very 
# ' similar to each other."_
# 
# us_world_dt <- us_world_dt %>% arrange (EDST) %>% filter (EQRT == 1)  # %>% print(n = nrow(.))
# 
# ' _"Then sort the subset of routes that connect environmentally similar ports 
# ' (identified above) by number of voyages, and create two priority lists:_
# '   a. _Routes with high traffic (one end of the list)._
# '   b. _Routes with very low traffic (the other end of the list)"._
# 
# us_world_dt <- us_world_dt %>% arrange ( desc(TRIPS)) %>% 
#              filter (TQRT == 1 | TQRT == 3 ) # %>% print(n = nrow(.))
# 
# ' _"One further qualification... If possible select 2(b) with another criterion 
# ' also in mind: ports that are currently low traffic that we expect to become
# ' high traffic (because of changes in infrastructure, etc). This would set
# ' us up nicely for future before-after comparisons."_
# 
#  ***** BEGIN: --OMITTING THIS SECTION 16.01.2018 AS THERE IS NOT ENOUGH DATA AVAILABALE *****
# 
# get port information from external file
# port_info <- read_excel("/Users/paul/Box Sync/CU_NIS-WRAPS/170727_port_information/160322_57_ports_selection.xlsx")
#   port_info # %>% print(n = nrow(.))
# 
# keep port information that is relavant to the list created here 
# port_info <- port_info %>% 
#   filter ( PLACE_ID %in% c(us_world_dt$PRTA, us_world_dt$PRTB) )
#   %>% print(n = nrow(.))
# 
#  select columns, set 0's to NAs, convert types - get a cleaner table
# port_info <- port_info %>% select("PLACE_ID", "CHANGES") %>% 
#              mutate(CHANGES = replace(CHANGES, CHANGES == 0, NA)) %>% 
#              na.omit() %>% mutate(PLACE_ID = as.numeric(PLACE_ID)) 
# 
# left join changes to table  
# us_world_dt <- left_join (us_world_dt, port_info, by = c("PRTA" = "PLACE_ID")) 
# us_world_dt <- left_join (us_world_dt, port_info, by = c("PRTB" = "PLACE_ID"))
# 
# merge columns and drop columns
# us_world_dt <- us_world_dt %>% mutate(CHANGES = coalesce(CHANGES.x, CHANGES.y)) %>%
#   select(-one_of(c("CHANGES.x", "CHANGES.y"))) 
# 
# replace character in `Changes` column, for Excel compatibility
# us_world_dt$CHANGES <- gsub("\\+", "more ", us_world_dt$CHANGES)
# us_world_dt$CHANGES <- gsub("\\-", "less ", us_world_dt$CHANGES)
# 
#  ***** END: -- OMITTING THIS SECTION 16.01.2018 AS THERE IS NOT ENOUGH DATA AVAILABALE *****
# 
# ' Print and save final list:
# us_world_dt <- us_world_dt %>% arrange (desc(TQRT), desc(TRIPS), desc(RISK)) # %>% print(n = nrow(.))
# 
# ' Saving for R 
# save (us_world_dt, file =
#   "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps_output__current_routes_selected.Rdata")
# 
# ' Saving for humans and external viewers:
# write_excel_csv ( us_world_dt, 
#                  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps_output__current_routes_selected.csv",
#                  na = "NA", append = FALSE, col_names = TRUE)

#' # Create maps
#'
#' ## Prepare tables to be mapped
#'
#' Shortlisted samples are in `us_world_dt`, and all routes outgoing from selected
#' samples in query `selected_samples` are in `us_world`. Change as needed.

# drawn_routes <- us_world_dt # filtered routes
drawn_routes <- us_world # full routes

#' This could be written up as function. Dividing point columns for `geom_line()`:
pointa <- dplyr::select(drawn_routes, c("ROUTE", "RISK", "EDST", "TRIPS", 
                                        "PALATI", "PALONG", "PORTA", "COUNA"))
pointb <- dplyr::select(drawn_routes, c("ROUTE", "RISK", "EDST", "TRIPS", 
                                        "PBLATI", "PBLONG", "PORTB", "COUNB"))
                                        
#' Rename variables to match each other and other sata to be plotted:
names(pointa) <- c("ROUTE", "RISK", "EDST", "TRIPS", "LATI", "LONG", "PORT",
                   "COUN")
                                        
names(pointb) <- c("ROUTE", "RISK", "EDST", "TRIPS", "LATI", "LONG", "PORT",
                   "COUN")

#' Stack Data Frames (Tibbles) on top of each other so that they can be parsed by `geom_line()`:
points_all <- rbind(pointa, pointb)

#' Sort Tibble rows to check - each `ROUTE` should be there twice:
points_all <- dplyr::arrange(points_all, desc(ROUTE)) %>% print(n = nrow(.))

# Correct port names
points_all$PORT[points_all$PORT == "Wilmington(DE USA)"] <- "Wilmington"
points_all$PORT[points_all$PORT == "Vancouver(CAN)"] <- "Vancouver"
points_all$PORT[points_all$PORT == "Richmond(VA USA)"] <- "Richmond"
points_all$PORT[points_all$PORT == "Portland(OR USA)"] <- "Portland"

#' ## Prepare points to be be mapped
#'
#' Different colours for available samples (currently in `smpld_PID`) and queried
#' (/processed samples - currently in  `selected_samples`).

# Available but unprocessed samples are to get a different colour down
#  further but these vector overlap, and this messes with the colour assignment.
#  Un-overlapping them here
available_samples <- smpld_PID [smpld_PID %!in% selected_samples]

# 2.10.2018 not using mutate anymore, too complicated, using manual lookup 

points_all$COLOR <- as.character("skyblue")
points_all$COLOR[which (points_all$PORT %in% c("Honolulu", "Singapore",
  "Adelaide", "Chicago", "Baltimore", "Houston", "Long Beach", "Miami"))] <- as.character("green")


#' ## Prepare base layer 
#' 
#' Initially defining the base map, without Antarctica.

world <- map_data("world")
world <- world[ which (world$region != "Antarctica"), ]   # remove Antarctica

# bolted in: select port to label - find manually using `smpld %>% print(n = nrow(.))`
# and `unique(points_all$PORT)`
#  so far 
# ports_to_label <- c("Singapore", "Houston", "Honululu", "Chicago", "Adelaide", "Miami", "Long Beach", "Baltimore",
#                     "Buenos Aires", "Antwerp", "Rotterdam")

#' This could be written up as function.
#' 
#' ## Compose map 
#' 
#' US - WORLD connections - all

m1 <-  ggplot() + 
  geom_polygon (
    data = world, 
    aes (x=long, y = lat, group = group)
  ) + 
  coord_fixed (
    xlim = c(-170, 175),  ylim = c(-50, 80), ratio = 1.3
  ) +
 geom_line ( data = points_all, 
    aes (x = LONG, y = LATI, group = ROUTE, colour = log(RISK))
  ) +
  scale_colour_gradient2 (
     # low = "dodgerblue1", mid = "forestgreen" , high = "firebrick1" # changed for DL
     low = "forestgreen", mid = "forestgreen" , high = "forestgreen" # changed for DL
  ) + 
  geom_label_repel ( 
    data = distinct (points_all , PORT, .keep_all = TRUE), # %>% filter (PORT %in% ports_to_label),
    aes (LONG, LATI, label = PORT), 
    size = 3,
    segment.color = 'grey50'
  ) +
  
  geom_point (
    data = points_all, aes (points_all$LONG, points_all$LATI),
    fill=points_all$COLOR, colour="black", pch=21, size=3
  ) +
  xlab(
    "Longitude"
  ) +
  ylab(
    "Latitude"
  ) +
  # ggtitle (
  #  "Sequenced Samples and Connections"
  # ) +
  theme (
    legend.position="none"
  ) +
  theme (
    plot.title = element_text (hjust = 0.5)
  )

#' ## Map printing
#'
#' Use multiplot if desirable (likely won't render or render well) in `.pdf`
print(m1)

# ggsave("500_40_get_maps__map_cnnct.png", plot = last_plot(), 
#         device = "png", path = "/Users/paul/Box Sync/CU_NIS-WRAPS/170728_external_presentations/180910_neobiota/180831_plot_without_connections.pdf",
#         scale = 1, width = 8, height = 5, units = c("in"),
#         dpi = 300, limitsize = TRUE)

#'
#' # Session info
#' 
#' The code and output in this document were tested and generated in the 
#' following computing environment:
#+ echo=FALSE
sessionInfo()

#' # References 

