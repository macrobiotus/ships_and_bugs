#' ---
#' title: "Mapping samples"
#' author: "Paul Czechowski"
#' date: "May 7th, 2017"
#' output: pdf_document
#' toc: true
#' highlight: zenburn
#' bibliography: /Users/paul/Documents/CU_combined/Github/references.bib
#' ---
#'
#' # Preface
#' 
#' Please refer to `/Users/paul/Documents/CU_combined/Github/README.md` for a 
#' project overview. This code commentary is included in the R code itself and
#' can be rendered at any stage using 
#' `rmarkdown::render ("/Users/paul/Documents/CU_combined/Github/500_40_get_maps.R")`.
#' Please check the session info at the end of the document for further 
#' notes on the coding environment.
#'
#' # Environment preparation
#'
#' ## Package loading and cleaning of workspace
#+ message=FALSE, results='hide'

library ("matrixStats") # here used (anymore?) for column median
library ("readxl")      # to open excel files
library ("reshape2")    # plotting, table manipulation
library ("ggplot2")     # plotting, mapping
library ("tidyverse")   # to `write_excel_csv()`
library ("maps")        # mapping
library ("ggrepel")     # plot labelling
library ("grid")        # handle graphical objects
library ("gridExtra")   # handle graphical objects


#' ## Flushing buffer
#' 
rm(list=ls())     # for safety only


#' 
#' ## Functions
#'

'%!in%' <- function(x,y)!('%in%'(x,y))

#' 
#' # Data import
#' 
#' Data is imported using basic R functionality, and was generated by these scripts: 
#'
#'  *  `/Users/paul/Documents/CU_combined/Github/500_10_gather_predictor_tables.R`
#'  *  `/Users/paul/Documents/CU_combined/Github/500_20_get_predictor_euklidian_distances.R`

load (file = 
   "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_30_shape_matrices__output_predictor_data.Rdata")

#' # Formatting local sample inventory
#' 
#' ## Adding `PID`'s to sample inventory 
#' 
#' Adding port IDs (`"PTID"`) to sampled ports in inventory file.
#' Can't find Pearl Harbor in places file - likely because it is a
#' military base (Jim Corbett). 23.8.2017: I am using Honolulus port ID from
#' the Lloyd data for samples from Pearl Harbor. Pearl Harbour
#' previously was marked `"0000"`, now `"2503"`. This ID will now in the
#' data twice - be mindful of possible bugs downstream!

# get port names from inventory file for MANUAL lookup 
smpld_PORT <- unique (src_heap$INVE$PORT)

# added 25.04.2018 - added ports for which re-processing from old project data
#  was accomplished. This list will not grow so this is a (possibly shaky)
#  solution. The proper (?) Alternative _may_ be to add these samples to `src_heap$INVE$PORT`
#  via the input file in `/Users/paul/Documents/CU_combined/Github/500_10_gather_predictor_tables.R`
smpld_PORT <- append(smpld_PORT, c("Adelaide", "Chicago", "Singapore"))

#' Manual lookup of sampled ports via  
#' `open /Users/paul/Dropbox/NSF\ NIS-WRAPS\ Data/raw\ data\ for\ Mandana/PlacesFile_updated_Aug2017.xlsx -a "Microsoft Excel"`
#' This file needs to be the same as used by `~/Box\ Sync/CU_NIS-WRAPS/170720_code/170830_10_cleanup_tables.R`.

# bug chase 24.04.2018 - ADL SNGP route goes missing - but it is still here 
src_heap$ROUT %>% filter (PRTA %in% "3110"& PRTB %in% "1165" |
                          PRTB %in% "3110"& PRTA %in% "1165" )


#  alternatively try a fuzzy match with agrep()
#  Milne Inlet coded as Nanisivik (3371)
#  Pearl Harbour coded as Honolulu (2503)
# 24.04.2018 added    "PH",   "SP",   "AD",  "CH"   
#                     "2503","1165","3110","2907") 

smpld_PID <- c("3367", "2141", "2111", "3108", "7597",  "311", "2503", "2503",
                "238", "4021", "7598", "7976", "7975", "3381", "4899", "2331",
                "854", "3371", "1165", "3110", "2907")

# create concise inventory tibble 
 # 23.08.2017 duplicate harbour ID "2503" does not appear to be a problem

smpld <- data_frame (PORT = smpld_PORT, PTID = smpld_PID)

# this filename is variable and based on the script name 
save (smpld, file = 
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps__output__sampled_ports_df.Rdata")

#' # Selecting and ranking of routes connecting to samples in the freezer
#'
#' ## Finding routes connecting to samples in the freezer
#'
#' Route information is in `src_heap$ROUT`. Sampled port ids are in `smpld$PTID`
#' Defining sampled routes (`srout`) by matching sampled port ids
#' with start or end points of routes file, and subsetting routes file: 

srout <- filter(src_heap$ROUT, 
  PRTA %in% smpld$PTID & 
  PRTB %in% smpld$PTID)
  
# bug chase 24.04.2018 - ADL SNGP route goes missing - but it is still here - RESOLVED NOW 
src_heap$ROUT %>% filter (PRTA %in% "3110"& PRTB %in% "1165" |
                          PRTB %in% "3110"& PRTA %in% "1165" )
srout %>% filter (PRTA %in% "3110"& PRTB %in% "1165" |
                          PRTB %in% "3110"& PRTA %in% "1165" )

#' ## Checking number of comple cases
#'
#' High value of complete cases desirable, other cases can't be sorted
#' Complete cases higher for `170804_all_connected_ports.csv` rather then the other
#' file (see above). The route table at hand has already been filtered to which
#' environmental distances are available `(see /Users/paul/Documents/CU_combined/Github/500_30_shape_matrices.R`
#' line 312. Consequently (?) data is complete:

sum(complete.cases(srout)) / length(complete.cases(srout))

#' Route data is incomplete no cases (see above comments):

srout [!complete.cases(srout), ] # %>% print(n = nrow(.))

#' ## Add port names and countries
#' 
#' Add port names and countries (not correcting coordinates). Incomplete cases 
#' to Jim Corbett? Port name information is here (and should be 9,177 x 5): 
ports <- src_heap$PORT 

#' Adding in port name information for both route ends:
srout <- left_join (srout, ports[c("PID", "PORT", "COUN")],
  by = c("PRTA" = "PID"))   
names (srout)[names (srout) %in% c("PORT", "COUN")] <- c("PORTA", "COUNA")

srout <- left_join (srout, ports[c("PID", "PORT", "COUN")],
  by = c("PRTB" = "PID"))   
names (srout)[names (srout) %in% c("PORT", "COUN")] <- c("PORTB", "COUNB")

#' ## Removing incomplete cases
#' 
#' Incomplete cases can't be sorted and should be reported.
#' I am removing them here.
srout <-  srout [ which (complete.cases (srout)), ] 


#' ## Saving US outbound routes
#' 
#' Routes that start in the US and go to the world are saved:

# copying object - points depiction needs full table down below but
# `srout` will be shaped further in the following lines 

srout_all <- srout 
save (srout_all, file =
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps__output__US_outbound_routes.Rdata")

#' ## Route filtering
#' 
#' Can be deactivated, modified.

# test 24.04.2018 - are test sample in the route table?
# 6 * 2 routes expected for Long Beach // Miami // Houston // Baltimore 
# selected_samples = c("7597","2331","4899","854")

# test 25.04.2018 - are test sample in the route table?
# manual lookup via
# open /Users/paul/Dropbox/NSF\ NIS-WRAPS\ Data/raw\ data\ for\ Mandana/PlacesFile_updated_Aug2017.xlsx -a "Microsoft Excel"
#                     PH",  "SP",  "AD",  "CH"    "MI"    "BT"   "HT"    "LB"
selected_samples = c("2503","1165","3110","2907", "4899", "854", "2331", "7597") 

## CHANGE THIS LINE IF NECESSARY 
srout <- srout %>% filter (PRTA %in% selected_samples | 
                           PRTB %in% selected_samples ) # %>% print(n = nrow(.))


#' ## **Route ranking based on calculated rank**
#'
#' Ranking by `RISK` variable, printing, and keeping for mapping
us_world <- srout %>% arrange (desc (RISK), desc (ROUTE)) # %>%  print(n = nrow(.))

#' Saving for R 
save (us_world, file =
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps__output__current_routes_sorted.Rdata")

#' Saving for humans and external viewers:
write_excel_csv (us_world, 
                 "/Users/paul/Documents/CU_combined/DI_R_tables/500_40_get_maps__output__current_routes_sorted.csv",
                 na = "NA", append = FALSE, col_names = TRUE)

#' ## **Route ranking based on environmental distance and trips**
#'
#' Copying object, original object needs to be kept for mapping
us_world_dt <- us_world  # %>% print(n = nrow(.))

#' Add grouping variable indicating quartiles of `TRIPS`

# https://stackoverflow.com/questions/7508229/how-to-create-a-column-with-a-quartile-rank
us_world_dt <- within (us_world_dt, TQRT <- as.integer (cut (TRIPS, quantile (TRIPS,
  seq(0, 1, 1/3), na.rm = FALSE), include.lowest=TRUE))) # %>% print(n = nrow(.))

#' Add grouping variable indicating quartiles of `EDST`

us_world_dt <- within (us_world_dt, EQRT <- as.integer (cut (EDST, quantile (EDST,
  seq(0, 1, 1/3), na.rm = FALSE), include.lowest=TRUE))) # %>%  print(n = nrow(.))

#' _"Sort routes by environmental similarity (temp & salinity index). Then deal only with the
#' routes at the end of this continuum where ports that are being connected are very 
#' similar to each other."_

us_world_dt <- us_world_dt %>% arrange (EDST) %>% filter (EQRT == 1)  # %>% print(n = nrow(.))

#' _"Then sort the subset of routes that connect environmentally similar ports 
#' (identified above) by number of voyages, and create two priority lists:_
#'   a. _Routes with high traffic (one end of the list)._
#'   b. _Routes with very low traffic (the other end of the list)"._

us_world_dt <- us_world_dt %>% arrange ( desc(TRIPS)) %>% 
             filter (TQRT == 1 | TQRT == 3 ) # %>% print(n = nrow(.))

#' _"One further qualification... If possible select 2(b) with another criterion 
#' also in mind: ports that are currently low traffic that we expect to become
#' high traffic (because of changes in infrastructure, etc). This would set
#' us up nicely for future before-after comparisons."_

#  ***** BEGIN: --OMITTING THIS SECTION 16.01.2018 AS THERE IS NOT ENOUGH DATA AVAILABALE *****

# get port information from external file
# port_info <- read_excel("/Users/paul/Box Sync/CU_NIS-WRAPS/170727_port_information/160322_57_ports_selection.xlsx")
#   port_info # %>% print(n = nrow(.))
# 
# keep port information that is relavant to the list created here 
# port_info <- port_info %>% 
#   filter ( PLACE_ID %in% c(us_world_dt$PRTA, us_world_dt$PRTB) )
#   %>% print(n = nrow(.))
# 
#  select columns, set 0's to NAs, convert types - get a cleaner table
# port_info <- port_info %>% select("PLACE_ID", "CHANGES") %>% 
#              mutate(CHANGES = replace(CHANGES, CHANGES == 0, NA)) %>% 
#              na.omit() %>% mutate(PLACE_ID = as.numeric(PLACE_ID)) 
# 
# left join changes to table  
# us_world_dt <- left_join (us_world_dt, port_info, by = c("PRTA" = "PLACE_ID")) 
# us_world_dt <- left_join (us_world_dt, port_info, by = c("PRTB" = "PLACE_ID"))
# 
# merge columns and drop columns
# us_world_dt <- us_world_dt %>% mutate(CHANGES = coalesce(CHANGES.x, CHANGES.y)) %>%
#   select(-one_of(c("CHANGES.x", "CHANGES.y"))) 
# 
# replace character in `Changes` column, for Excel compatibility
# us_world_dt$CHANGES <- gsub("\\+", "more ", us_world_dt$CHANGES)
# us_world_dt$CHANGES <- gsub("\\-", "less ", us_world_dt$CHANGES)

#  ***** END: -- OMITTING THIS SECTION 16.01.2018 AS THERE IS NOT ENOUGH DATA AVAILABALE *****

#' Print and save final list:
us_world_dt <- us_world_dt %>% arrange (desc(TQRT), desc(TRIPS), desc(RISK)) # %>% print(n = nrow(.))

#' Saving for R 
save (us_world_dt, file =
  "/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_40_get_maps__output__current_routes_selected.Rdata")

#' Saving for humans and external viewers:
write_excel_csv ( us_world_dt, 
                 "/Users/paul/Documents/CU_combined/DI_R_tables/500_40_get_maps__output__current_routes_selected.csv",
                 na = "NA", append = FALSE, col_names = TRUE)

#' # Create maps
#'
#' ## Prepare tables to be mapped
#'
#' Shortlisted samples are in `us_world_dt`, and all routes outgoing from selected
#' samples in query `selected_samples` are in `us_world`. Change as needed.

drawn_routes <- us_world_dt 
# drawn_routes <- us_world

#' This could be written up as function. Dividing point columns for `geom_line()`:
pointa <- dplyr::select(drawn_routes, c("ROUTE", "RISK", "EDST", "TRIPS", 
                                        "PALATI", "PALONG", "PORTA", "COUNA"))
pointb <- dplyr::select(drawn_routes, c("ROUTE", "RISK", "EDST", "TRIPS", 
                                        "PBLATI", "PBLONG", "PORTB", "COUNB"))
                                        
#' Rename variables to match each other and other sata to be plotted:
names(pointa) <- c("ROUTE", "RISK", "EDST", "TRIPS", "LATI", "LONG", "PORT",
                   "COUN")
                                        
names(pointb) <- c("ROUTE", "RISK", "EDST", "TRIPS", "LATI", "LONG", "PORT",
                   "COUN")

#' Stack Data Frames (Tibbles) on top of each other so that they can be parsed by `geom_line()`:
points_all <- rbind(pointa, pointb)

#' Sort Tibble rows to check - each `ROUTE` should be there twice:
points_all <- dplyr::arrange(points_all, desc(ROUTE)) # %>% print(n = nrow(.))

#' ## Prepare points to be be mapped
#'
#' Different colours for available samples (currently in `smpld_PID`) and queried
#' (/processed samples - currently in  `selected_samples`).

# Available but unprocessed samples are to get a different colour down
#  further but these vector overlap, and this messes with the colour assignment.
#  Un-overlapping them here
available_samples <- smpld_PID [smpld_PID %!in% selected_samples ]

# the mutate command is nested, but this object can be plotted directly on the map
# points_tabl <- srout_all %>% filter (PRTA %in% smpld_PID |
#                                      PRTA %in% selected_samples ) %>%
#                                      distinct(PORTA, .keep_all = TRUE) %>%
#                                      select(c("PALATI", "PALONG", "PORTA", "PRTA")) %>% 
#                                      mutate (COLOR = ifelse(PRTA %in% selected_samples, "green",
#                                        ifelse(PRTA %in% available_samples, "orange", "grey")))

points_tabl <- srout_all %>% filter (PRTA %in% selected_samples ) %>%
                                     distinct(PORTA, .keep_all = TRUE) %>%
                                     select(c("PALATI", "PALONG", "PORTA", "PRTA")) %>% 
                                     mutate (COLOR = ifelse(PRTA %in% selected_samples, "green", NA))


#' ## Prepare base layer 
#' 
#' Initially defining the base map, without Antarctica.

world <- map_data("world")
world <- world[ which (world$region != "Antarctica"), ]   # remove Antarctica

# bolted in: select port to label - find manually using `smpld # %>% print(n = nrow(.))`
# and `unique(points_all$PORT)`
#  so far 
ports_to_label <- c("Singapore", "Houston", "Honululu", "Chicago", "Adelaide", "Miami", "Long Beach", "Baltimore")

#' This could be written up as function.
#' 
#' ## Compose map 
#' 
#' US - WORLD connections - all

m1 <-  ggplot() + 
  geom_polygon (
    data = world, 
    aes (x=long, y = lat, group = group)
  ) + 
  coord_fixed (
    xlim = c(-170, 175),  ylim = c(-50, 80), ratio = 1.3
  ) +
  geom_line ( data = points_all, 
    aes (x = LONG, y = LATI, group = ROUTE, colour = log(RISK))
  ) +
  scale_colour_gradient2 (
    low = "dodgerblue1", mid = "forestgreen" , high = "firebrick1"
  ) +
  geom_label_repel ( 
    data = distinct (points_all , PORT, .keep_all = TRUE) %>% filter (PORT %in% ports_to_label),
    aes (LONG, LATI, label = PORT), 
    size = 3,
    segment.color = 'grey50'
  ) +
  geom_point ( data = points_tabl, aes(points_tabl$PALONG, points_tabl$PALATI), colour = points_tabl$COLOR
  ) + 
  
  xlab(
    "Longitude"
  ) +
  ylab(
    "Latitude"
  ) +
  ggtitle (
    "Sequenced Samples and Connections"
  ) +
  theme (
    legend.position="bottom"
  ) +
  theme (
    plot.title = element_text (hjust = 0.5)
  )

#' ## Map printing
#'
#' Use multiplot if desirable (likely won't render or render well) in `.pdf`
print(m1)

ggsave("500_40_get_maps__map_cnnct.png", plot = last_plot(), 
         device = "png", path = "/Users/paul/Box Sync/CU_NIS-WRAPS/170728_external_presentations/171128_wcmb/180429_wcmb_talk",
         scale = 1, width = 8, height = 5, units = c("in"),
         dpi = 300, limitsize = TRUE)


#'
#' # Session info
#' 
#' The code and output in this document were tested and generated in the 
#' following computing environment:
#+ echo=FALSE
sessionInfo()

#' # References 

