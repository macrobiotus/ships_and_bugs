#' ---
#' title: "Get input data tables for Mixed Effect Models"
#' author: "Paul Czechowski"
#' date: "27-April-2020"
#' output: pdf_document
#' toc: true
#' highlight: zenburn
#' bibliography: ./references.bib
#' ---
#' 
#' This script needs all R scripts named `500_*.R` to have run successfully,
#' apart from `/Users/paul/Documents/CU_combined/Github/500_05_UNIFRAC_behaviour.R`
#' It should then be called using a shell script. It will only accept certain files
#' currently, and otherwise abort. For further information understand section Environment
#' preparation. Also check `/Users/paul/Documents/CU_combined/Github/210_get_mixed_effect_model_results.sh`
#'
#' This code commentary is included in the R code itself and can be rendered at
#' any stage using `rmarkdown::render ("/Users/paul/Documents/CU_combined/Github/500_80_get_mixed_effect_model_tables.R")`.
#' Please check the session info at the end of the document for further 
#' notes on the coding environment.
#' 
#' # Environment preparation
#'
#' Empty buffer.

rm(list=ls())

#' Load Packages

library ("tidyverse") # dplyr and friends
library ("gdata")     # matrix functions
library ("reshape2")  # melting

#' Functions

# Loaded from helper script:
source("/Users/paul/Documents/CU_combined/Github/500_00_functions.R")

#' Define parameters. Call script via `Rscript --vanilla foo.R input_foo.foo output_fara.fara`.

args = commandArgs(trailingOnly=TRUE)

#' Test if there is at least one argument: If not, return an error.

# 06.09.2019 - I am passing in more descriptive filenames, so this three fold
#   if block can probably be cleaned out and simplified

if (length(args)==0) {
  
  stop("At least source file needs to be specified.\n", call.=TRUE)

} else if (length(args)==1) {
  
  message("Destination path not set, `get_path()` will use default")
  
  args[2] = NULL # for compatibility with function `get_path()` in `/Users/paul/Documents/CU_combined/Github/500_00_functions.R`

} else if (length(args)>=2) {
 

  message("1st argument defined as: \"", args[1], "\".\n")
  message("2nd argument defined as: \"", args[2], "\".\n")
  
  message("Using default destinations, if less then 7 output paths are defined.")
  
  # creating unique string to add to input files in case input filenames are identical
  uniqstr <- format(Sys.time(), "%Y-%b-%d-%H-%M-%S")
  
  # Definition of second argument: `args[2]` will define write path of collapsed 
  #   response matrix down below in call `write.csv(r_mat_clpsd, file = args[2])`
  #   this file name should be somewhat related to the input file name. Otherwise a 
  #   generic name is assigned here, since the file contents are determined by the 
  #   last-passed distance matrix file in `args[1]`. 
  args[3] <- get_path(args[1], args[2], paste0("collapsed_response_distance_matrix_", uniqstr), ".csv")
  
  message("3rd argument defined as: \"", args[3], "\".\n")


  # Definition of third default arguments `args[3]` will define write path of readily formatted model data 
  #  call `write.csv(model_data, file = args[3])`
  args[4] <- get_path(args[1], args[2],  paste0("model_data_", uniqstr), ".csv")
  
  message("4th argument defined as: \"", args[4], "\".\n")
  
  # Definition of fourth default arguments `args[4]` will define write path 
  #  for variable plots by ecoregion  in call (and subsequent) 
  # `pdf("args[4]", one file = TRUE)`
  args[5] <- get_path(args[1], args[2], paste0("variables_by_ecoregion_", uniqstr), ".pdf")
  
  message("5th argument defined as: \"", args[5], "\".\n")
  
  # Definition of fifth default arguments `args[5]` will define write path 
  #  all text output generated by `sink(file = args[4], append = TRUE,
  #  type = "message", split = TRUE)` command,  
  args[6] = get_path(args[1], args[2], paste0("modelling_results_", uniqstr), ".txt")
  
  message("6th argument defined as: \"", args[6], "\".\n")
  
  # Definition of sixth default arguments `args[6]` will define write path 
  #  for model graphic summary in `ggsave()` call. 
  #  type = "message", split = TRUE)` command,  
  args[7] = get_path(args[1], args[2], paste0("modelling_results_", uniqstr), ".pdf")
  
  message("7th argument defined as: \"", args[7], "\".\n")
  
  # Definition of seventh default arguments `args[7]` will define image legend 
  #  in `ggsave()` call. 
  args[8] = "Biologic distance metric changes between ports, depending on ecoregion-crossing and environmental distance (in SD)."
  
  message("8th argument defined as: \"", args[8], "\".\n")

}


#'
#' <!-- #################################################################### -->
#'
#' # Data read-in
#'
#' ## Predictors 1 of 1: Environmental Distances
#'
#' This data is available for many ports (more ports then shipping routes)
load("/Users/paul/Documents/CU_combined/Zenodo/R_Objects/500_30_shape_matrices__output__mat_env_dist_full.Rdata")

# checking - see debugging notes: some port numbers in row-/colnames are not unique
#          - see debugging notes: row- and colnames are undefined, bu seemingly consitent with above
#             so likley less problematic
mat_env_dist_full[35:50, 35:50]

#'
#' <!-- -------------------------------------------------------------------- -->
#'      
#' ## Response: A distance matrix as produced by Qiime 2 (UNIFRAC or Jacquard)
#'
#' First command line parameter

resp_path <- args[1]

# message("Using distance matrix path from test condition.")

# deep set - currently tested
# resp_path <- c("/Users/paul/Documents/CU_combined/Zenodo/Qiime/185_eDNA_samples_Eukaryotes_core_metrics_unweighted_UNIFRAC_distance_artefacts/185_unweighted_unifrac_distance_matrix.tsv")
# deep set - not yet tested
# resp_path <- c("/Users/paul/Documents/CU_combined/Zenodo/Qiime/185_eDNA_samples_Eukaryote-shallow_core_metrics_unweighted_UNIFRAC_distance_artefacts/185_unweighted_unifrac_distance_matrix.tsv")

resp_mat  <- read.table(file = resp_path, sep = '\t', header = TRUE)

# checking import and format
resp_mat[35:50, 35:50]
resp_mat[01:10, 01:10]
class(resp_mat)

#' <!-- #################################################################### -->
#'
#'
#' <!-- #################################################################### -->
#'
#' # Data formatting 
#' 
#' ## Responses 1 of 3: Unifrac distance matrix as produced by Qiime 2
#'
#' Need to be done before the predictors: Matrix fields need to be averaged (09-Apr-2019: using median)
#' across replicates. The resulting ports descriptors are then used to shape
#' predictor data. **NOT** Inverting Unifrac distances to closeness in order to match 
#' `(1 / src_heap$ROUT$EDST)`, which also is a measure of closeness.

# substitute dots `.` in column headers with minus `-` to match row names
colnames(resp_mat) <- gsub( '\\.' , '-', colnames(resp_mat))

# set data frame row-names correctly 
rownames(resp_mat) <- resp_mat$X; resp_mat$X <- NULL

# check data frame row and column formatting - better to have them equal 
any(colnames(resp_mat) == rownames(resp_mat))

# Create empty receiving matrix from data frame ...
r_mat_clpsd <- get_collapsed_responses_matrix(resp_mat)

# Collapsed matrix should receive data for samples: 
#    (deep) Unifrac input:  PH SI AD BT HN HT LB MI AW CB HS NO OK PL PM RC RT GH WL ZB
# (shallow) Unifrac input:  PH SI AD BT HN HT LB MI AW CB HS NA NO OK PL PM RC RT VN GH WL ZB

r_mat_clpsd <- fill_collapsed_responses_matrix(r_mat_clpsd, resp_mat)

## Commenting out matrix writing 12.11.2019
# write.csv(r_mat_clpsd, file = args[3])
dim(r_mat_clpsd)
#'
#' <!-- -------------------------------------------------------------------- -->
#'      

message("Port names of current matrix are: ",  paste0(colnames(r_mat_clpsd), " "))

# 12-Jun-2019 for automatic implementation here a safety check to enable crude automatisation. 
# 05-Sep-2019 if loop implemented.
# 27-Apr-2020 used `open "/Users/paul/Documents/CU_NIS-WRAPS/170727_port_information/190926_PlacesFile_updated_Aug2017.xlsx" -a "Microsoft Excel"` for corrections
#              as previously 

expected_colnames_deepest <- c("PH", "SI", "AD", "BT", "HN", 
                               "HT", "LB", "MI", "AW", "CB", 
                               "HS", "NO", "OK", "PL", "PM", 
                               "RC", "RT", "GH", "WL", "ZB")
                               
# After Antwerp ("AW") Buenos Aires ("BA") added before Coos Bay ("CB")
expected_colnames_shallow <- c("PH", "SI", "AD", "BT", "HN",
                               "HT", "LB", "MI", "AW", "CB",
                               "HS", "NA", "NO", "OK", "PL",
                               "PM", "RC", "RT", "VN", "GH",
                               "WL", "ZB")

# Set port numbers, nbased on detected columns
if ( identical (colnames (r_mat_clpsd), expected_colnames_deepest)) { 
  
    message("Setting port selection for deep rarefaction depth")
    message("Expected ports are: ", paste0(expected_colnames_deepest, " ") )

    
    port_number_subset <- c("2503", "1165", "3110",  "854", "2503", 
                            "2331", "7597", "4899",  "576", "2141", 
                            "3367", "3381", "7598",  "238",  "193", 
                            "4777",  "830", "4538", "7975", "1675")
    
    } else if ( identical (colnames (r_mat_clpsd), expected_colnames_shallow)) {
    
    
    # After Antwerp ("576") Buenos Aires ("BA") added before Coos Bay ("2141")
    message("Setting port selection for shallow rarefaction depth")
    message("Expected ports are: ", paste0(expected_colnames_shallow, " ") )

    
    port_number_subset <- c("2503", "1165", "3110",  "854", "2503", 
                            "2331", "7597", "4899",  "576", "2141", 
                            "3367", "3108", "3381", "7598",  "238", 
                            "193", "4777",  "830",  "311", "4538",
                            "7975", "1675")
    } else {
    
    stop( "Port names can't be matched automatically. Manual intervention is necessary.\n", call.=FALSE)
    
}

# find spelling mistakes in rout port number subset:
# port_number_subset %in% rownames(mat_trips)

#'
#' ## Predictors 2 of 2: Environmental distances
#'
# quick and dirty - manual lookup
#   use order  of response matrix (!!!)
#   here "PH","SP","AD","CH", "BT", "HN", "HT", "LB", "MI"
#   improve (!!!) this. Manual lookup via:
#   `open "/Users/paul/Documents/CU_NIS-WRAPS/170727_port_information/190926_PlacesFile_updated_Aug2017.xlsx" -a "Microsoft Excel"`

# 05-Sep-2019 vector define via if loop above 
mat_env_dist <- mat_env_dist_full[port_number_subset, port_number_subset]

mat_env_dist[lower.tri(mat_env_dist, diag = FALSE)] <- NA

# predictors - copy names - make automatic !! 
colnames(mat_env_dist) <- colnames(r_mat_clpsd)
rownames(mat_env_dist) <- rownames(r_mat_clpsd)

message("Environmental distance matrix is:")
print(mat_env_dist)
message("With ", sum( !is.na( mat_env_dist ) )," elements.")

message("Response distance matrix is:")
print(r_mat_clpsd) 
message("With ", sum( !is.na( r_mat_clpsd ) )," elements.")

#'
#' <!-- #################################################################### -->
#'
#'
#' <!-- #################################################################### -->
#'
#' ## Getting Dataframes for modelling 

# create named list with objects
mat_list <- list (r_mat_clpsd, mat_env_dist)

mat_list <- setNames(mat_list, c("resp_unifrac", "pred_env"))

# Are all matrix dimesions are the same?
var(c(sapply (mat_list, dim))) == 0

# Are all matrices symmetrical and have the same rownames and column names
all(sapply (mat_list, rownames) == sapply (mat_list, colnames))

# melt data frames for joining 
df_list <- lapply (mat_list, function(x) data.frame(x)  %>%
                             rownames_to_column("PORT") %>%
                             melt(., id.vars = "PORT"))

# join dataframes and name columns - "NA" (Nanaimo) becomes "NA." to not be R's "NA"
#  also one column isn't a factor variable - correcting this
model_data_raw <- df_list %>% reduce(inner_join, by = c("PORT", "variable")) %>%
                          setNames(c("PORT", "DEST", toupper(names(mat_list))))
class(model_data_raw)

levels(model_data_raw$DEST)[ which (levels(model_data_raw$DEST) == "NA.")] <- "NX"
model_data_raw$PORT <- as.factor(model_data_raw$PORT)
levels(model_data_raw$PORT)[ which (levels(model_data_raw$PORT) == "NA")] <- "NX"

# check this table carefully for consistent column names
# model_data_raw

# remove incomplete cases - only ignoring lower half of matrix, otherwise remove 
#  column selector
model_data <- model_data_raw %>% filter(complete.cases(.))
class(model_data)
model_data

# add ecoregion as per:
#   @Costello, M. J., Tsai, P., Wong, P. S., Cheung, A. K. L., Basher, Z. 
#   and Chaudhary, C. (2017) “Marine biogeographic realms and species endemicity,” 
#   Nature Communications. Springer US, 8(1), p. 1057. doi: 10.1038/s41467-017-01121-2..
#   write as function !!!!!!!!
#   here using REALMS, there are 30 Realms listed in the paper (Fig 1, Fig2b)

model_data <- model_data %>% add_column("ECO_PORT" = NA)
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("HN", "PH"), "17", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("SI"), "13", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("AD"), "26", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("CH","BT","MI", "HT", "NO", "WL"), "11", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("LB", "CB", "OK", "PL", "RC", "VN", "NX", "HS"), "7", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("PM", "BA"), "24", model_data$"ECO_PORT"))
model_data <- model_data %>% mutate (ECO_PORT = ifelse( .$"PORT"  %in% c("AW", "RT", "GH", "ZB"), "3", model_data$"ECO_PORT"))

model_data <- model_data %>% add_column("ECO_DEST" = NA)
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("HN", "PH"), "17", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("SI"), "13", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("AD"), "26", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("CH","BT","MI", "HT", "NO", "WL"), "11", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("LB", "CB", "OK", "PL", "RC", "VN", "NX", "HS"), "7", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("PM", "BA"), "24", model_data$"ECO_DEST"))
model_data <- model_data %>% mutate (ECO_DEST = ifelse( .$"DEST"  %in% c("AW", "RT",  "GH", "ZB"), "3", model_data$"ECO_DEST"))

model_data <- model_data %>% add_column("ECO_DIFF" = NA)
model_data <- model_data %>% mutate (ECO_DIFF = ifelse(ECO_PORT == ECO_DEST , FALSE, TRUE))

#'
#' <!-- #################################################################### -->
#'
#' <!-- #################################################################### -->
#'

# Sorting columns
model_data <- model_data %>% arrange(PORT, DEST)

model_data$PORT <- as.factor(model_data$PORT)
model_data$DEST <- as.factor(model_data$DEST)
model_data$ECO_DIFF <- as.factor(model_data$ECO_DIFF)

# write data as per input path - keep close to variable selection below
write_csv(model_data, path = args[4])

#' <!-- #################################################################### -->
#'
#' # Session info
#'
#' The code and output in this document were tested and generated in the
#' following computing environment:
#+ echo=FALSE
sessionInfo()

#' # References
